{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fff025a",
   "metadata": {},
   "source": [
    "# Projeto 2 de Intelig√™ncia Artificial\n",
    "### Disciplina: Introdu√ß√£o √† Intelig√™ncia Artificial - UnB\n",
    "### Turma: 01, 2025/2\n",
    "### Professor: Dibio\n",
    "\n",
    "### Integrantes:\n",
    "#>- Adrielly Vit√≥ria Costa de Lima - 231018973\n",
    "\n",
    "#>- Carlos Cau√£ Rocha da Silva - 231034304\n",
    "\n",
    "#>- Leticia Gon√ßalves Bomfim - 241002411\n",
    "\n",
    "O link da p√°gina do reposit√≥rio √©: https://github.com/Schatten900/proj2-iaa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b58b4a",
   "metadata": {},
   "source": [
    "## Aqui descreveremos as instru√ß√µes de quais extens√µes devem ser baixadas e como rodar o projeto para Linux\n",
    "\n",
    "1- Roda o de treinamento.py\n",
    "\n",
    "2- Roda o ajustar_limiar.py\n",
    "\n",
    "3- Se der um valor diferente do que consta no arquivo avaliar.py √© s√≥ trocar o valor\n",
    "\n",
    "4- Roda o avaliar.py para ele vai classificar as imagens\n",
    "\n",
    "5- Roda o interpretar.py para ver os resultados e as fotos mostrando as diferen√ßas\n",
    "\n",
    "6- Roda a main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf96b8",
   "metadata": {},
   "source": [
    "## Dataset, Interpretabilidade e Resultados_Infer√™ncia\n",
    "   A estrutura apresentada no diret√≥rio do projeto foi organizada para seguir exatamente as etapas descritas no m√©todo de Katafuchi & Tokunaga (2020) proposto pelo trabalho, que prop√µe um diagn√≥stico de doen√ßas em plantas utilizando detec√ß√£o de anomalias n√£o supervisionada baseada na reconstru√ß√£o de cores por meio de um modelo Generative Adversarial Network (pix2pix).\n",
    "\n",
    "   A pasta dataset cont√©m os dados brutos fornecidos pelo professor e est√° dividida conforme solicitado no enunciado:\n",
    "\n",
    "    Healthy_Train50 ‚Äì 50 imagens de folhas saud√°veis usadas para treinar o modelo generativo.\n",
    "\n",
    "    Healthy_Test50 ‚Äì 50 imagens saud√°veis usadas para testar o sistema.\n",
    "\n",
    "    Disease_Test100 ‚Äì 100 imagens de folhas doentes empregadas na etapa final de infer√™ncia.\n",
    "\n",
    "   Estas subdivis√µes permitem reproduzir o setup experimental do artigo original, que exige um modelo treinado com folhas saud√°veis, de forma que qualquer falha na reconstru√ß√£o indique a presen√ßa de anomalias.\n",
    "\n",
    "   A pasta interpretabilidade re√∫ne as figuras geradas durante as an√°lises com Grad-CAM, conforme solicitado no projeto.\n",
    "Arquivos como figura_0.png, figura_1.png, etc., mostram os mapas de ativa√ß√£o que destacam as regi√µes da folha que mais influenciam o modelo no processo de detec√ß√£o de anomalia. Essa etapa permite verificar visualmente se a rede est√° focando nas √°reas lesionadas.\n",
    "\n",
    "  Por fim, a pasta resultados_inferencia cont√©m as imagens geradas pelo modelo pix2pix e os resultados finais do m√©todo de reconstru√ß√£o. Nela, cada folha original passa por tr√™s representa√ß√µes principais:\n",
    "\n",
    "    real_leaf ‚Äì √© a imagem real da folha (saud√°vel ou doente) usada como entrada.\n",
    "\n",
    "    gerada_leaf ‚Äì √© a imagem reconstru√≠da pelo modelo pix2pix, representando como a folha deveria ser se estivesse saud√°vel, segundo o modelo treinado.\n",
    "\n",
    "    delta_leaf ‚Äì mapa de diferen√ßas entre a imagem real e a reconstru√≠da, revelando visualmente o √≠ndice de cor usado como m√©trica de anomalia no artigo. Quanto maior e mais concentrado o delta, maior a presen√ßa de doen√ßa.\n",
    "\n",
    "Essa organiza√ß√£o faz o treinamento apenas com folhas saud√°veis, gera imagens de reconstru√ß√µes com pix2pix, calcula do √≠ndice de cor para anomalia e gera a visualiza√ß√£o interpret√°vel da decis√£o do modelo (Grad-CAM). Assim, essa parte do c√≥digo documenta claramente cada etapa executada, facilita testes adicionais e fornece o necess√°rio para compor a an√°lise de resultados exigida no projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d041f845",
   "metadata": {},
   "source": [
    "## Pasta Service\n",
    "### Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd26a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "\n",
    "def carregar_imagem(caminho):\n",
    "    \"\"\"\n",
    "    Carrega uma √∫nica imagem para infer√™ncia.\n",
    "    Sem uso de tf.data, apenas cv2.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(caminho)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img / 127.5 - 1.0\n",
    "    return img.astype(\"float32\")\n",
    "\n",
    "def carregar_imagem_cv2(caminho):\n",
    "    caminho = caminho.decode(\"utf-8\")\n",
    "    img = cv2.imread(caminho)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img / 127.5 - 1.0\n",
    "    return img.astype(\"float32\")\n",
    "\n",
    "\n",
    "def wrapper_processamento(caminho):\n",
    "    img = tf.numpy_function(carregar_imagem_cv2, [caminho], tf.float32)\n",
    "    img.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
    "    return img, img\n",
    "\n",
    "\n",
    "def criar_dataset_treino(pasta=\"dataset/Healthy_Train50\", batch_size=2):\n",
    "\n",
    "    caminhos = tf.data.Dataset.list_files(pasta + \"/*\", shuffle=True)\n",
    "\n",
    "    dataset = caminhos.map(\n",
    "        wrapper_processamento,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(100)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791372e9",
   "metadata": {},
   "source": [
    "   As fun√ß√µes carregar_imagem e carregar_imagem_cv2 executam, em sequ√™ncia: Leitura e Convers√£o (carregam a imagem usando OpenCV (cv2) e convertem de BGR para RGB), Redimensionamento (ajustam todas as imagens para o tamanho fixo de 128 pixels (IMG_SIZE)) e Normaliza√ß√£o (mapeiam os valores dos pixels para o intervalo [-1.0, 1.0] (f√≥rmula: img / 127.5 - 1.0). Isso √© crucial para o treinamento est√°vel de Redes Neurais Generativas (como o Pix2Pix))\n",
    " \n",
    "   Enquanto isso, a fun√ß√£o criar_dataset_treino utiliza o TensorFlow dataset API para criar um pipeline de dados de alto desempenho:\n",
    "‚Ä¢\twrapper_processamento: √â o \"pacote\" que permite ao tf.data chamar a fun√ß√£o OpenCV/NumPy para processamento, garantindo que o shape da imagem seja definido para (128, 128, 3).\n",
    "‚Ä¢\treturn img, img: Prepara o dataset para o treinamento de um Autoencoder/Pix2Pix, onde a entrada (X) √© a imagem saud√°vel e a sa√≠da (Y) esperada √© a pr√≥pria imagem saud√°vel (X=Y).\n",
    "‚Ä¢\tOtimiza√ß√£o: A fun√ß√£o implementa otimiza√ß√µes como processamento paralelo, caching, shuffling e prefetching para evitar gargalos de I/O durante o treinamento.\n",
    "\n",
    "   Assim, o c√≥digo prepara apenas o conjunto de treinamento, composto pelas 50 imagens de folhas saud√°veis. Durante o teste, a folha doente apresentar√° um alto erro de reconstru√ß√£o no pix2pix, que ser√° o indicador da anomalia, conforme o m√©todo do artigo de Katafuchi & Tokunaga.\n",
    "\n",
    "### Discriminador.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293838a9",
   "metadata": {},
   "source": [
    "   A arquitetura do Discriminador √© baseada no modelo PatchGAN, usado em Pix2Pix, onde ele tenta classificar se uma regi√£o da imagem √© real ou gerado, em vez de classificar a imagem inteira. O Discriminador de um Pix2Pix recebe duas imagens: a imagem de entrada (inp - a folha original) e a imagem alvo (tar - a imagem que o Gerador produziu, que neste contexto seria a folha reconstru√≠da).\n",
    "\n",
    "Gera√ß√£o do Grad-CAM no Discriminador:\n",
    "   A fun√ß√£o gerar_gradcam_discriminador implementa o algoritmo Grad-CAM,usado para visualiza√ß√£o e coloca em pr√°tica que:\n",
    "    1.\tO modelo √© treinado em folhas saud√°veis.\n",
    "    2.\tQuando uma folha doente √© testada, o Discriminador tende a dar uma pontua√ß√£o baixa para a combina√ß√£o (Folha Original, Folha Reconstru√≠da).\n",
    "    3.\tO Grad-CAM identifica quais pixels ou regi√µes da imagem mais influenciaram a decis√£o do Discriminador.\n",
    "    \n",
    "   Como entradas recebe o Discriminador j√° treinado, a imagem de entrada (img_in) e a imagem reconstru√≠da (img_out), faz a identifica√ß√£o da camada, onde o c√≥digo encontra a √∫ltima camada convolucional do Discriminador (ultima_conv), cria um modelo tempor√°rio que tem a sa√≠da da √∫ltima camada convolucional E a sa√≠da final do Discriminador e calcula o gradiente da sa√≠da  em rela√ß√£o aos mapas de caracter√≠sticas (conv_out) da √∫ltima camada convolucional. O gradiente indica a import√¢ncia de cada feature map para a decis√£o final.\n",
    "   \n",
    "   J√° o c√°lculo dos pesos (grads) √© feito com o gradiente, que √© globalmente agrupado (tf.reduce_mean) para obter os pesos m√©dios de import√¢ncia de cada canal de feature map. A gera√ß√£o do mapa de ativa√ß√£o multiplica os pesos m√©dios (grads) pelos mapas de caracter√≠sticas (conv_out) e soma-os (tf.reduce_sum).\n",
    "   \n",
    "   Por fim, aplica uma fun√ß√£o de ativa√ß√£o ReLU (np.maximum(cam, 0)) para focar apenas nas contribui√ß√µes positivas e, em seguida, normaliza o resultado (entre 0 e 1). Como resultado temos que o cam √© um mapa de calor que mostra as regi√µes da folha que o Discriminador considerou mais importantes.\n",
    "   \n",
    "### Gerador.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b3bc2",
   "metadata": {},
   "source": [
    "   Este c√≥digo define a arquitetura do Gerador da Rede Advers√°ria Generativa (GAN) do projeto, utilizando a estrutura U-Net. O Gerador √© respons√°vel por receber uma folha original e produzir a folha reconstru√≠da, ou seja, saud√°vel.\n",
    "   \n",
    "   O Gerador foi pensado como uma arquitetura de Autoencoder com Conex√µes de Salto, o que define a U-Net:\n",
    "‚Ä¢\tEncoder (d1 a d6): Reduz progressivamente a imagem de entrada at√© um gargalo (bottleneck) de 4 por 4 pixels.\n",
    "‚Ä¢\tDecoder (u1 a u5): Aumenta o tamanho espacial do gargalo de volta para 128 por 128.\n",
    "‚Ä¢\tlayers.Concatenate(): Esta √© a caracter√≠stica central da U-Net. Em cada etapa do Decoder (u1 a u5), a sa√≠da √© concatenada com o mapa de caracter√≠sticas correspondente do Encoder (d5 a d1). Isso permite que informa√ß√µes de alta resolu√ß√£o e detalhes finos (perdidos no gargalo) sejam passadas diretamente para a fase de reconstru√ß√£o.\n",
    "‚Ä¢\tSa√≠da: A camada final Conv2DTranspose com ativa√ß√£o tanh produz a imagem reconstru√≠da. A fun√ß√£o mapeia a sa√≠da para o intervalo [-1.0, 1.0], que corresponde √† normaliza√ß√£o aplicada na entrada (carregar_imagem).\n",
    "\n",
    "   O Gerador √© treinado para atuar como um Autoencoder Identidade para folhas saud√°veis. Sua fun√ß√£o √© realizar o treinamento, recebendo uma folha saud√°vel e aprendendo a reconstru√≠-la perfeitamente. E testar, recebendo uma folha doente e falhando na reconstru√ß√£o das √°reas afetadas, produzindo uma imagem que se parece com uma folha saud√°vel. A diferen√ßa entre a entrada doente e a sa√≠da reconstru√≠da √© o mapa de anomalias que ser√° usado para o diagn√≥stico.\n",
    "\n",
    "### Gradcam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2154785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def encontrar_ultima_conv(modelo):\n",
    "    \"\"\"\n",
    "    Percorre o modelo inteiro, inclusive blocos Sequential,\n",
    "    para encontrar a √∫ltima camada Conv2D.\n",
    "    \"\"\"\n",
    "    ultima_conv = None\n",
    "\n",
    "    def explorar(layers):\n",
    "        nonlocal ultima_conv\n",
    "        for layer in layers:\n",
    "            # se for Conv2D\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                ultima_conv = layer\n",
    "\n",
    "            # se for um bloco Sequential, explorar dentro\n",
    "            if isinstance(layer, tf.keras.Model) or isinstance(layer, tf.keras.Sequential):\n",
    "                explorar(layer.layers)\n",
    "\n",
    "    explorar(modelo.layers)\n",
    "    return ultima_conv\n",
    "\n",
    "\n",
    "def gerar_gradcam(modelo, img_normalizada):\n",
    "\n",
    "    entrada = tf.expand_dims(img_normalizada, axis=0)\n",
    "\n",
    "    # achar a √∫ltima camada conv2D\n",
    "    ultima_conv = encontrar_ultima_conv(modelo)\n",
    "    if ultima_conv is None:\n",
    "        raise ValueError(\"Nenhuma camada Conv2D encontrada no modelo (nem dentro de Sequential).\")\n",
    "\n",
    "    # criar modelo que mapeia entrada -> (featuremap, sa√≠da final)\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=modelo.inputs,\n",
    "        outputs=[ultima_conv.output, modelo.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_out, pred = grad_model(entrada)\n",
    "        loss = tf.reduce_mean(pred)\n",
    "\n",
    "    grads = tape.gradient(loss, conv_out)\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    cam = tf.reduce_sum(weights * conv_out[0], axis=-1)\n",
    "\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / (np.max(cam) + 1e-8)\n",
    "\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf965e1",
   "metadata": {},
   "source": [
    "   Essa parte do c√≥digo diz respeito √† implementa√ß√£o do algoritmo Grad-CAM, projetado para funcionar em qualquer modelo sequencial ou com blocos internos, como o Discriminador ou Gerador definidos anteriormente.\n",
    "Encontra a √∫ltima camada convolucional, usando uma abordagem de recurs√£o (explorar(layers)) para atravessar a estrutura de camadas do modelo, inclusive explorando dentro de blocos definidos como Sequential ou Model. Assim, garante que a √∫ltima Conv2D de todo o grafo seja identificada.\n",
    "\n",
    "   A fun√ß√£o gerar_gradcam aplica o algoritmo do Grad-CAM. Ou seja, o modelo de gradiente (grad_model, cria um modelo auxiliar que tem duas sa√≠das, sendo eles os mapas de caracter√≠sticas da ultima_conv e a sa√≠da final de predi√ß√£o do modelo (modelo.output). Al√©m disso, utiliza tf.GradientTape() para calcular o gradiente da sa√≠da final (loss = tf.reduce_mean(pred)) em rela√ß√£o aos mapas de caracter√≠sticas da ultima_conv (conv_out). Este gradiente indica a import√¢ncia relativa de cada mapa de caracter√≠stica para a predi√ß√£o.\n",
    "   \n",
    "   J√° o c√°lculo dos pesos usa o gradiente globalmente agrupado (tf.reduce_mean) para obter o peso de import√¢ncia de cada canal de feature map. Enquanto o mapa de calor (cam) √© obtido pela multiplica√ß√£o pontual dos pesos pelos mapas de caracter√≠sticas (conv_out) e somando os resultados ao longo do eixo dos canais.\n",
    "   \n",
    "   Para a normaliza√ß√£o, aplicamos a fun√ß√£o de ativa√ß√£o ReLU (np.maximum(cam, 0)) para remover contribui√ß√µes negativas e normaliza o mapa final para o intervalo [0, 1].\n",
    "   \n",
    "   Dessa forma, a visualiza√ß√£o pode ocorrer tanto no discriminador quanto no gerador. No Discriminador identifica as regi√µes que mais convenceram o discriminador de que a reconstru√ß√£o √© saud√°vel e no Gerador pode ser usado para ver quais regi√µes da imagem de entrada o Gerador est√° usando para produzir a sa√≠da reconstru√≠da.\n",
    "   \n",
    "### Metrics.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9cb474",
   "metadata": {},
   "source": [
    "![Exemplo](interpretabilidade/figura_0.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48e45a",
   "metadata": {},
   "source": [
    "![Exemplo](interpretabilidade/figura_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a5c77",
   "metadata": {},
   "source": [
    "![Exemplo](interpretabilidade/figura_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0743e0fa",
   "metadata": {},
   "source": [
    "![Exemplo](interpretabilidade/figura_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aea984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import color\n",
    "\n",
    "def mapa_deltaE_ciede2000(real, gerada):\n",
    "    #normaliza para [0,1\n",
    "    if real.dtype == np.uint8:\n",
    "        real = real.astype(\"float32\") / 255.0\n",
    "    if gerada.dtype == np.uint8:\n",
    "        gerada = gerada.astype(\"float32\") / 255.0\n",
    "    \n",
    "    lab_real = color.rgb2lab(real)\n",
    "    lab_gerada = color.rgb2lab(gerada)\n",
    "\n",
    "    deltaE = color.deltaE_ciede2000(lab_real, lab_gerada)\n",
    "    \n",
    "    return deltaE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97966b",
   "metadata": {},
   "source": [
    "   O sistema come√ßa com o pr√©-processamento e carregamento de dados eficiente, onde as imagens de folhas saud√°veis s√£o lidas, redimensionadas para 128 por 128 pixels e normalizadas para o intervalo [-1.0, 1.0]. O dataset √© preparado para alimentar o modelo com a imagem de entrada e a imagem alvo id√™nticas (X=Y).\n",
    "   \n",
    "   A arquitetura do sistema √© composta por duas redes principais: o Gerador e o Discriminador. O Gerador que serve como um autoencoder que comprime e depois descompacta a imagem, mantendo a fidelidade estrutural atrav√©s das conex√µes diretas entre o encoder e o decoder. Enquanto o Discriminador que for√ßa o Gerador a produzir resultados realistas.\n",
    "   \n",
    "   Finalmente, o sistema inclui ferramentas essenciais de avalia√ß√£o e visualiza√ß√£o. A fun√ß√£o mapa_deltaE_ciede2000 implementa a m√©trica, uma medida de diferen√ßa de cor que ser√° usada para gerar o mapa de anomalias, onde altos valores de entre a folha doente original e a reconstru√ß√£o saud√°vel indicam a √°rea da doen√ßa. Para a visualiza√ß√£o, o c√≥digo fornece uma implementa√ß√£o do Grad-CAM, capaz de identificar as regi√µes exatas da imagem que mais influenciaram a decis√£o do Discriminador, fornecendo uma explica√ß√£o visual para o diagn√≥stico. Em conjunto, o c√≥digo estabelece um pipeline desde o carregamento otimizado dos dados at√© a constru√ß√£o do modelo e as ferramentas de avalia√ß√£o exigidas pelo projeto.\n",
    "\n",
    "### Ajustar_limiar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from inferencia import carregar_modelo, desnormalizar\n",
    "from services.dataset import carregar_imagem\n",
    "from services.metrics import mapa_deltaE_ciede2000\n",
    "\n",
    "def ajustar():\n",
    "\n",
    "    saudaveis = glob.glob(\"dataset/Healthy_Test50/*\")\n",
    "    doentes = glob.glob(\"dataset/Disease_Test100/*\")\n",
    "\n",
    "    gerador = carregar_modelo()\n",
    "\n",
    "    erros_saudaveis = []\n",
    "    erros_doentes = []\n",
    "\n",
    "    for img_path in saudaveis:\n",
    "        real_norm = carregar_imagem(img_path)\n",
    "        real = desnormalizar(real_norm)\n",
    "        fake = gerador(np.expand_dims(real_norm,0))[0].numpy()\n",
    "        fake = desnormalizar(fake)\n",
    "        deltaE = mapa_deltaE_ciede2000(real, fake)\n",
    "        erros_saudaveis.append(np.mean(deltaE))\n",
    "\n",
    "    for img_path in doentes:\n",
    "        real_norm = carregar_imagem(img_path)\n",
    "        real = desnormalizar(real_norm)\n",
    "        fake = gerador(np.expand_dims(real_norm,0))[0].numpy()\n",
    "        fake = desnormalizar(fake)\n",
    "        deltaE = mapa_deltaE_ciede2000(real, fake)\n",
    "        erros_doentes.append(np.mean(deltaE))\n",
    "\n",
    "    print(\"\\nM√©dias:\")\n",
    "    print(\"Saud√°veis:\", np.mean(erros_saudaveis))\n",
    "    print(\"Doentes  :\", np.mean(erros_doentes))\n",
    "\n",
    "    print(\"\\nSugest√£o de limiar:\")\n",
    "    print((np.mean(erros_saudaveis)+np.mean(erros_doentes))/2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ajustar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cee184",
   "metadata": {},
   "source": [
    "![Sa√≠da](imagens/limiar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42f0a3",
   "metadata": {},
   "source": [
    "   Este c√≥digo finaliza o pipeline do projeto, implementando a etapa de avalia√ß√£o do modelo treinado e a defini√ß√£o do limiar de detec√ß√£o de anomalias. Ele testa o Gerador nos conjuntos de teste de folhas saud√°veis e doentes.\n",
    "   \n",
    "   O c√≥digo itera sobre os dois conjuntos de teste, sendo eles saud√°veis e doentes, para calcular o Erro de Reconstru√ß√£o m√©dio de cada imagem. Para cada imagem segue o seguinte fluxo: Carregamento e Normaliza√ß√£o, onde o real_norm = carregar_imagem(img_path) carrega e normaliza a folha original para o intervalo [-1.0, 1.0]. A seguir, temos a gera√ß√£o por fake = gerador(np.expand_dims(real_norm,0))[0].numpy() que passa a folha original pelo gerador para obter a folha reconstru√≠da. E, por fim, a imagem real (real) e a imagem reconstru√≠da (fake) s√£o desnormalizadas para o intervalo [0, 1] ou [0, 255] para serem compat√≠veis com o c√°lculo da m√©trica de cor. J√° o c√°lculo de m√©trica se d√° por deltaE = mapa_deltaE_ciede2000(real, fake), que calcula o mapa de diferen√ßa de cor percept√≠vel  entre a folha original e a reconstru√ß√£o e o erro m√©dio por np.mean(deltaE), que calcula o erro de reconstru√ß√£o m√©dio para a imagem inteira.\n",
    "   \n",
    "### Avaliar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a03b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from inferencia import carregar_modelo, desnormalizar\n",
    "from services.dataset import carregar_imagem\n",
    "from services.metrics import mapa_deltaE_ciede2000\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "LIMIAR = 3.325781\n",
    "\n",
    "def avaliar():\n",
    "\n",
    "    saudaveis = glob.glob(\"dataset/Healthy_Test50/*\")\n",
    "    doentes   = glob.glob(\"dataset/Disease_Test100/*\")\n",
    "\n",
    "    print(f\"Saud√°veis: {len(saudaveis)}\")\n",
    "    print(f\"Doentes: {len(doentes)}\")\n",
    "\n",
    "    if len(saudaveis) == 0 and len(doentes) == 0:\n",
    "        print(\"Nenhuma imagem encontrada.\")\n",
    "        return\n",
    "\n",
    "    gerador = carregar_modelo()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    todos = saudaveis + doentes\n",
    "    labels = [0]*len(saudaveis) + [1]*len(doentes)\n",
    "\n",
    "    for img_path, true_label in zip(todos, labels):\n",
    "\n",
    "        real_norm = carregar_imagem(img_path)\n",
    "        real = desnormalizar(real_norm)\n",
    "\n",
    "        fake_norm = gerador(np.expand_dims(real_norm, axis=0))[0].numpy()\n",
    "        fake = desnormalizar(fake_norm)\n",
    "\n",
    "        deltaE = mapa_deltaE_ciede2000(real, fake)\n",
    "        erro = np.mean(deltaE)\n",
    "\n",
    "        pred = 1 if erro > LIMIAR else 0\n",
    "\n",
    "        y_true.append(true_label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    if len(y_true) == 0:\n",
    "        print(\"Nenhuma imagem v√°lida processada.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n M√âTRICAS:\\n\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, zero_division=0))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, zero_division=0))\n",
    "    print(\"F1-score :\", f1_score(y_true, y_pred, zero_division=0))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    avaliar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbf1314",
   "metadata": {},
   "source": [
    "![Sa√≠da](imagens/avaliar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7dea9a",
   "metadata": {},
   "source": [
    "   Este parte do c√≥digo implementa a etapa de avalia√ß√£o final de desempenho do sistema de diagn√≥stico de anomalias, transformando o erro de reconstru√ß√£o em uma decis√£o de classifica√ß√£o bin√°ria e calculando as m√©tricas de desempenho mais relevantes.\n",
    "   \n",
    "   O c√≥digo usa um valor de limiar fixo, presumivelmente determinado na etapa anterior, que separou o erro de reconstru√ß√£o m√©dio das imagens saud√°veis e doentes. E, tamb√©m carrega todos os caminhos das imagens de teste (50 saud√°veis, 100 doentes) e cria a lista de r√≥tulos verdadeiros (y_true), onde 0 significa Saud√°vel e 1 significa Doente.\n",
    "   \n",
    "   Ap√≥s isso, o c√≥digo itera sobre todas as 150 imagens de teste. Cada imagem √© processada pelo Gerador, gerando sua reconstru√ß√£o saud√°vel e tamb√©m √© calculado o erro m√©dio de cor entre a imagem original e a reconstru√ß√£o, esse erro √© comparado com o limiar e se erro > 3.325781, a imagem √© classificada como doente (pred = 1) ou se erro <= 3.325781, a imagem √© classificada como Saud√°vel (pred = 0). Por fim, o r√≥tulo verdadeiro (true_label) e a predi√ß√£o (pred) s√£o armazenados em y_true e y_pred.\n",
    "   \n",
    "### Carregar_Modelo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c161b",
   "metadata": {},
   "source": [
    "   Essa parte do c√≥digo √© respons√°vel por reconstruir o modelo gerador e carregar nele os pesos previamente treinados. Ela come√ßa verificando se o arquivo indicado, que armazena os pesos do modelo, realmente existe. Caso o arquivo n√£o seja encontrado no diret√≥rio especificado, a fun√ß√£o interrompe o processo e informa ao usu√°rio que o arquivo de pesos n√£o est√° dispon√≠vel, evitando erros posteriores de execu√ß√£o.\n",
    "   \n",
    "   Se o arquivo estiver presente, a fun√ß√£o prossegue chamando construir_gerador, que monta a arquitetura do modelo gerador utilizada no sistema. Em seguida, o modelo √© explicitamente constru√≠do com uma forma de entrada padr√£o de 128√ó128 pixels e tr√™s canais de cor, garantindo que sua estrutura esteja completamente inicializada antes do carregamento dos pesos.\n",
    "   \n",
    "   Ap√≥s essa prepara√ß√£o, os pesos salvos no arquivo s√£o carregados no modelo, restaurando o estado aprendido durante o treinamento. Quando o processo √© conclu√≠do com sucesso, uma mensagem √© exibida ao usu√°rio confirmando que o carregamento foi realizado corretamente. Por fim, a fun√ß√£o retorna o modelo j√° configurado e pronto para ser usado nas etapas de infer√™ncia ou avalia√ß√£o.\n",
    "   \n",
    "### Infer√™ncia.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferir.py\n",
    "#\n",
    "# Carrega o gerador salvo em \"gerador_treinado.h5\"\n",
    "# e realiza infer√™ncia e classifica√ß√£o.\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from services.dataset import carregar_imagem\n",
    "from services.metrics import mapa_deltaE_ciede2000\n",
    "from services.gerador import construir_gerador\n",
    "\n",
    "\n",
    "\n",
    "def carregar_modelo(path=\"gerador_treinado.h5\"):\n",
    "    return tf.keras.models.load_model(path, compile=False)\n",
    "\n",
    "def desnormalizar(img):\n",
    "    img = (img + 1) * 127.5\n",
    "    return np.clip(img, 0, 255).astype(np.uint8)\n",
    "    \n",
    "def inferir(img_path, limiar=25):\n",
    "\n",
    "    gerador = carregar_modelo()\n",
    "\n",
    "    real_norm = carregar_imagem(img_path)\n",
    "    real = desnormalizar(real_norm)\n",
    "\n",
    "    fake_norm = gerador(np.expand_dims(real_norm, axis=0))[0].numpy()\n",
    "    fake = desnormalizar(fake_norm)\n",
    "\n",
    "    deltaE = mapa_deltaE_ciede2000(real, fake)\n",
    "    erro = np.mean(deltaE)\n",
    "\n",
    "    classe = \"Folha DOENTE\" if erro > limiar else \"Folha SAUD√ÅVEL\"\n",
    "\n",
    "    os.makedirs(\"resultados_inferencia\", exist_ok=True)\n",
    "    nome = os.path.basename(img_path)\n",
    "\n",
    "    cv2.imwrite(f\"resultados_inferencia/real_{nome}\", cv2.cvtColor(real, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(f\"resultados_inferencia/gerada_{nome}\", cv2.cvtColor(fake, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(f\"resultados_inferencia/deltaE_{nome}\", deltaE)\n",
    "\n",
    "    print(\"Classifica√ß√£o:\", classe)\n",
    "    print(\"Erro m√©dio:\", erro)\n",
    "\n",
    "    return classe\n",
    "\n",
    "def carregar_modelo_pesos(caminho=\"gerador_treinado.weights.h5\"):\n",
    "    if not os.path.exists(caminho):\n",
    "        print(\"Erro: pesos n√£o encontrados!\")\n",
    "        return None\n",
    "    \n",
    "    modelo = construir_gerador()\n",
    "    modelo.build((None, 128, 128, 3))\n",
    "    modelo.load_weights(caminho)\n",
    "    print(\"Pesos carregados com sucesso!\")\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e010a47f",
   "metadata": {},
   "source": [
    "   Essa parte √© respons√°vel pela etapa de infer√™ncia do sistema, isto √©, o momento em que o modelo j√° treinado √© utilizado para analisar novas imagens de folhas e decidir se elas est√£o saud√°veis ou doentes, nele, a reconstru√ß√£o de uma folha saud√°vel serve como refer√™ncia para identificar anomalias na imagem original.\n",
    "   \n",
    "   H√° duas fun√ß√µes para carregar o modelo treinado, uma utiliza diretamente um arquivo .h5 contendo toda a estrutura e pesos do modelo, enquanto a outra reconstr√≥i a arquitetura a partir do zero e ent√£o carrega apenas os pesos salvos. Ambas as abordagens permitem restaurar o estado aprendido durante o treinamento. A fun√ß√£o desnormalizar (desnormalizar(img)), tem fun√ß√£o de converter imagens que est√£o no intervalo [-1, 1] de volta para o formato tradicional de pixels entre 0 e 255.\n",
    "   \n",
    "   J√° a fun√ß√£o central (inferir(img_path, limiar=25)), tem fun√ß√£o de carregar e normalizar a imagem de entrada como mesma feito no treinamento. Depois disso, o modelo gerador produz uma reconstru√ß√£o da imagem, representando a vers√£o ideal dessa folha. Tanto a imagem real quanto a reconstru√≠da passam pela desnormaliza√ß√£o para que possam ser visualizadas e comparadas adequadamente.\n",
    "   \n",
    "   A compara√ß√£o entre as duas imagens √© feita atrav√©s da m√©trica DeltaE CIEDE2000, desse c√°lculo resulta um mapa de diferen√ßas entre real e reconstru√≠da, al√©m de um valor m√©dio que sintetiza o qu√£o discrepante a imagem original √© da vers√£o saud√°vel produzida pelo gerador. Quanto maior esse erro m√©dio, maior a probabilidade de que a folha apresente algum tipo de doen√ßa ou anomalia. A classifica√ß√£o √© feita comparando esse erro m√©dio com um limiar previamente ajustado. Quando o erro ultrapassa o limiar, a folha √© considerada doente; quando est√° abaixo, √© classificada como saud√°vel. Esse limiar √© calculado em outra etapa do projeto, justamente para permitir uma separa√ß√£o mais precisa entre as duas classes.\n",
    "   \n",
    "   Ao fim, a pasta chamada resultados_inferencia salva tr√™s arquivos, sendo eles a imagem real, a reconstru√ß√£o gerada pelo modelo e o mapa DeltaE que destaca as diferen√ßas entre ambas. O script informa no terminal qual foi a classe atribu√≠da √† imagem e qual foi o valor do erro m√©dio encontrado, al√©m de retornar o resultado da classifica√ß√£o. Dessa forma, o arquivo inferir.py encapsula todo o processo de diagn√≥stico, desde o carregamento do modelo at√© a gera√ß√£o das imagens e dos indicadores.\n",
    "\n",
    "### Interpretar.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb478f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from carregar_modelo import carregar_modelo_pesos\n",
    "from services.dataset import carregar_imagem\n",
    "from services.metrics import mapa_deltaE_ciede2000\n",
    "from services.discriminador import gerar_gradcam_discriminador\n",
    "from services.discriminador import construir_discriminador\n",
    "from inferencia import desnormalizar\n",
    "\n",
    "\n",
    "os.makedirs(\"interpretabilidade\", exist_ok=True)\n",
    "\n",
    "\n",
    "def interpretar_imagem(caminho_img, gerador, idx):\n",
    "\n",
    "    # imagem real normalizada [-1,1]\n",
    "    real_norm = carregar_imagem(caminho_img)\n",
    "    real = desnormalizar(real_norm)\n",
    "\n",
    "    entrada = np.expand_dims(real_norm, axis=0)\n",
    "\n",
    "    # reconstru√ß√£o\n",
    "    fake_norm = gerador(entrada, training=False)[0].numpy()\n",
    "    fake = desnormalizar(fake_norm)\n",
    "\n",
    "    # ŒîE2000\n",
    "    deltaE = mapa_deltaE_ciede2000(real, fake)\n",
    "\n",
    "    # Grad-CAM do DISCRIMINATOR\n",
    "    discriminador = construir_discriminador()\n",
    "    cam = gerar_gradcam_discriminador(discriminador, real_norm, fake_norm)\n",
    "    cam = cv2.resize(cam, (128, 128))\n",
    "\n",
    "    # heatmap\n",
    "    heatmap = cv2.applyColorMap((cam * 255).astype(\"uint8\"), cv2.COLORMAP_JET)\n",
    "    overlay = cv2.addWeighted(heatmap, 0.5, real, 0.5, 0)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "    ax[0].imshow(real)\n",
    "    ax[0].set_title(\"Original\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    ax[1].imshow(fake)\n",
    "    ax[1].set_title(\"Reconstru√≠da\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    ax[2].imshow(deltaE, cmap=\"inferno\")\n",
    "    ax[2].set_title(\"ŒîE2000\")\n",
    "    ax[2].axis(\"off\")\n",
    "\n",
    "    ax[3].imshow(cam, cmap=\"jet\")\n",
    "    ax[3].set_title(\"Grad-CAM (Discriminador)\")\n",
    "    ax[3].axis(\"off\")\n",
    "\n",
    "    ax[4].imshow(overlay)\n",
    "    ax[4].set_title(\"Overlay\")\n",
    "    ax[4].axis(\"off\")\n",
    "\n",
    "    nome = f\"interpretabilidade/figura_{idx}.png\"\n",
    "    plt.savefig(nome, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"‚úî Figura salva: {nome}\")\n",
    "\n",
    "\n",
    "def executar_interpretabilidade():\n",
    "\n",
    "    gerador = carregar_modelo_pesos()\n",
    "\n",
    "    imagens = (\n",
    "        glob.glob(\"dataset/Healthy_Test50/*\")[:2] +\n",
    "        glob.glob(\"dataset/Disease_Test100/*\")[:2]\n",
    "    )\n",
    "\n",
    "    print(f\"\\nRodando interpretabilidade para {len(imagens)} imagens...\\n\")\n",
    "\n",
    "    for i, img in enumerate(imagens):\n",
    "        interpretar_imagem(img, gerador, i)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    executar_interpretabilidade()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e9485",
   "metadata": {},
   "source": [
    "![Sa√≠da](imagens/interpretar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eca989",
   "metadata": {},
   "source": [
    "   J√° nessa parte do c√≥digo, passa a lidar com um segundo modo de carregamento do gerador, permitindo que o modelo seja reconstru√≠do manualmente antes de receber apenas os pesos treinados. Para isso, o c√≥digo verifica se o arquivo contendo os pesos realmente existe e, caso contr√°rio, interrompe o processo para evitar falhas. \n",
    "   \n",
    "   Quando o arquivo √© encontrado, o gerador √© montado a partir da fun√ß√£o de constru√ß√£o j√° utilizada no treinamento e depois inicializado com as dimens√µes esperadas, garantindo compatibilidade na hora de aplicar os pesos. Ap√≥s essa prepara√ß√£o, o carregamento √© realizado e uma confirma√ß√£o √© exibida, indicando que o modelo est√° pronto para ser usado em infer√™ncias. Essa abordagem oferece flexibilidade adicional ao projeto, permitindo tanto o carregamento do modelo completo quanto apenas dos pesos, dependendo da necessidade.\n",
    "   \n",
    "### Main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49018836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "#\n",
    "# Menu principal para:\n",
    "#   1. Treinar o modelo\n",
    "#   2. Realizar infer√™ncia em imagem aleat√≥ria do dataset de teste\n",
    "#\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from treinamento import treinar\n",
    "from inferencia import inferir\n",
    "\n",
    "# Pastas do dataset de teste\n",
    "PASTAS_TESTE = [\n",
    "    \"dataset/Disease_Test100\",\n",
    "    \"dataset/Healthy_Test50\"\n",
    "]\n",
    "\n",
    "\n",
    "def escolher_imagem_aleatoria():\n",
    "    \"\"\"\n",
    "    Seleciona uma imagem aleat√≥ria do dataset de teste.\n",
    "    \"\"\"\n",
    "    pasta = random.choice(PASTAS_TESTE)\n",
    "\n",
    "    imagens = [\n",
    "        arq for arq in os.listdir(pasta)\n",
    "        if arq.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "    ]\n",
    "\n",
    "    if not imagens:\n",
    "        raise RuntimeError(f\"Nenhuma imagem encontrada na pasta {pasta}\")\n",
    "\n",
    "    nome = random.choice(imagens)\n",
    "    caminho = os.path.join(pasta, nome)\n",
    "\n",
    "    print(f\"\\nüåø Imagem sorteada para infer√™ncia: {caminho}\\n\")\n",
    "    return caminho\n",
    "\n",
    "\n",
    "def executar_inferencia():\n",
    "    imagem = escolher_imagem_aleatoria()\n",
    "    resultado = inferir(imagem)   # <-- removido checkpoint_dir\n",
    "    print(f\"\\nResultado Final da Infer√™ncia: {resultado}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def executar_treinamento():\n",
    "    \"\"\"\n",
    "    Executa o treinamento do modelo.\n",
    "    \"\"\"\n",
    "    print(\"\\nIniciando treinamento...\\n\")\n",
    "    treinar()\n",
    "    print(\"\\nTreinamento finalizado!\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    while True:\n",
    "        print(\"\\n==============================\")\n",
    "        print(\"     SISTEMA PIX2PIX IA\")\n",
    "        print(\"==============================\")\n",
    "        print(\"1 - Treinar modelo\")\n",
    "        print(\"2 - Inferir imagem aleat√≥ria do teste\")\n",
    "        print(\"3 - Sair\")\n",
    "        print(\"==============================\\n\")\n",
    "\n",
    "        opcao = input(\"Escolha uma op√ß√£o: \")\n",
    "\n",
    "        if opcao == \"1\":\n",
    "            executar_treinamento()\n",
    "\n",
    "        elif opcao == \"2\":\n",
    "            executar_inferencia()\n",
    "\n",
    "        elif opcao == \"3\":\n",
    "            print(\"Encerrando...\")\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            print(\"Op√ß√£o inv√°lida!\")\n",
    "    exit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191a2d2",
   "metadata": {},
   "source": [
    "   O c√≥digo main.py √© o menu principal e o ponto de entrada do seu sistema de diagn√≥stico de folhas, contendo a interface de controle. Sua fun√ß√£o principal √© permitir ao usu√°rio escolher entre treinar o modelo (treinar(), importado) ou realizar infer√™ncia (inferir(), importado).\n",
    "   \n",
    "   A fun√ß√£o escolher_imagem_aleatoria √© respons√°vel por sortear, de forma equilibrada, uma imagem aleat√≥ria tanto do conjunto de folhas saud√°veis quanto do conjunto de folhas doentes para ser usada no teste imediato de infer√™ncia.\n",
    "   \n",
    "   As fun√ß√µes executar_treinamento e executar_inferencia chamam os m√≥dulos de treinamento e infer√™ncia, respectivamente, garantindo que o fluxo do programa seja mantido. A fun√ß√£o main orquestra este menu em um loop cont√≠nuo at√© que o usu√°rio escolha sair.\n",
    "   \n",
    "### Treinamento.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeae5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "from services.dataset import criar_dataset_treino\n",
    "from services.gerador import construir_gerador\n",
    "from services.discriminador import construir_discriminador\n",
    "\n",
    "\n",
    "LR = 2e-4\n",
    "LAMBDA_L1 = 50     # menor = treinamento mais r√°pido\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "\n",
    "def perda_discriminador(real_output, fake_output):\n",
    "    BCE = losses.BinaryCrossentropy(from_logits=True)\n",
    "    return 0.5 * (BCE(tf.ones_like(real_output), real_output) +\n",
    "                  BCE(tf.zeros_like(fake_output), fake_output))\n",
    "\n",
    "\n",
    "def perda_gerador_gan(fake_output):\n",
    "    BCE = losses.BinaryCrossentropy(from_logits=True)\n",
    "    return BCE(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "\n",
    "def perda_l1(real, fake):\n",
    "    return tf.reduce_mean(tf.abs(real - fake))\n",
    "\n",
    "\n",
    "opt_g = Adam(LR, beta_1=0.5)\n",
    "opt_d = Adam(LR, beta_1=0.5)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def treinar_batch(gerador, discriminador, real_in, real_tgt):\n",
    "\n",
    "    with tf.GradientTape() as tape_g, tf.GradientTape() as tape_d:\n",
    "\n",
    "        fake_img = gerador(real_in, training=True)\n",
    "\n",
    "        disc_real = discriminador([real_in, real_tgt], training=True)\n",
    "        disc_fake = discriminador([real_in, fake_img], training=True)\n",
    "\n",
    "        g_gan = perda_gerador_gan(disc_fake)\n",
    "        g_l1 = perda_l1(real_tgt, fake_img)\n",
    "\n",
    "        g_total = g_gan + LAMBDA_L1 * g_l1\n",
    "\n",
    "        d_total = perda_discriminador(disc_real, disc_fake)\n",
    "\n",
    "    grad_g = tape_g.gradient(g_total, gerador.trainable_variables)\n",
    "    grad_d = tape_d.gradient(d_total, discriminador.trainable_variables)\n",
    "\n",
    "    opt_g.apply_gradients(zip(grad_g, gerador.trainable_variables))\n",
    "    opt_d.apply_gradients(zip(grad_d, discriminador.trainable_variables))\n",
    "\n",
    "    return g_total, d_total\n",
    "\n",
    "\n",
    "def treinar():\n",
    "\n",
    "    dataset = criar_dataset_treino(batch_size=BATCH_SIZE)\n",
    "\n",
    "    gerador = construir_gerador()\n",
    "    discriminador = construir_discriminador()\n",
    "\n",
    "    print(\"\\n=========== INICIANDO TREINAMENTO ===========\")\n",
    "\n",
    "    for ep in range(1, EPOCHS + 1):\n",
    "\n",
    "        g_loss_ep = 0\n",
    "        d_loss_ep = 0\n",
    "        batches = 0\n",
    "\n",
    "        for real_in, real_tgt in dataset:\n",
    "            g_loss, d_loss = treinar_batch(gerador, discriminador, real_in, real_tgt)\n",
    "            g_loss_ep += g_loss\n",
    "            d_loss_ep += d_loss\n",
    "            batches += 1\n",
    "\n",
    "        print(f\"√âpoca {ep}/{EPOCHS} | \"\n",
    "              f\"G_Loss = {g_loss_ep/batches:.4f} | \"\n",
    "              f\"D_Loss = {d_loss_ep/batches:.4f}\")\n",
    "\n",
    "    print(\"\\n=========== TREINAMENTO FINALIZADO ===========\\n\")\n",
    "\n",
    "    gerador.save(\"gerador_treinado.h5\")\n",
    "    print(\"Modelo salvo como gerador_treinado.h5\")\n",
    "\n",
    "    return gerador\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    treinar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06584ef",
   "metadata": {},
   "source": [
    "![Sa√≠da](imagens/treinamento.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1365490e",
   "metadata": {},
   "source": [
    "   Essa parte do c√≥digo √© respons√°vel pelo treinamento. O c√≥digo apresentado √© o m√≥dulo Treinamento (treinar.py), que define e executa o processo de aprendizado da GAN, respons√°vel por gerar as reconstru√ß√µes de folhas saud√°veis. O treinamento √© regido por par√¢metros chave como a taxa de aprendizado e o fator de peso da perda de reconstru√ß√£o, crucial para for√ßar a fidelidade da imagem gerada.\n",
    "   \n",
    "   A din√¢mica do treinamento √© centralizada na fun√ß√£o treinar_batch, onde o gerador cria uma imagem falsa, em seguida, o discriminador avalia a imagem falsa e a imagem real. As perdas s√£o ent√£o calculadas. A perda total do gerador √© uma combina√ß√£o da perda adversarial e da perda L1. Por sua vez, a perda do discriminador √© a soma da sua capacidade de classificar corretamente os pares reais e os pares falsos, usando gradientes calculados via tf.GradientTape, os otimizadores Adam separados que atualizam os pesos de cada rede de forma competitiva. \n",
    "   \n",
    "   O loop principal treinar esse processo, iterando sobre batches do dataset de folhas saud√°veis. Ao final, o gerador treinado √© salvo no arquivo gerador_treinado.h5, tornando-o pronto para ser usado na infer√™ncia e detec√ß√£o de anomalias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
